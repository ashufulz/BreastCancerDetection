# -*- coding: utf-8 -*-
"""BreastCancerDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BPMQH1J4GI1KbOfw7rVaXmlu3r1wRvq6
"""

#Description: Detect Breast Cancer based on data

#Importing Libraries
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

#Loading Dataset
from google.colab import files
uploaded = files.upload()

df = pd.read_csv('BreastCancerDetection.csv')
df.head()

df.shape

df.isna().sum()

df = df.dropna(axis=1)

df.shape

df['diagnosis'].value_counts()

sns.countplot(df['diagnosis'], label='count')

#Encoding the categorical data values
from sklearn.preprocessing import LabelEncoder
le_Y = LabelEncoder()
df.iloc[:, 1] = le_Y.fit_transform(df.iloc[:, 1].values)

df.iloc[:, 1]

#Creating a pairplot
sns.pairplot(df.iloc[:, 1:7], hue='diagnosis')

#Getting the correlation
df.iloc[:, 1:12].corr()

#Visualizing the correlation
plt.figure(figsize=(10, 10))
sns.heatmap(df.iloc[:, 1:12].corr(), annot=True, fmt='.0%')

#Splitting the dataset
X = df.iloc[:, 2:31].values
Y = df.iloc[:, 1].values

#Splitting the dataset into 75% training and 25% testing
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=0)

#Feature scaling the data
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()

X_train = sc.fit_transform(X_train)
X_test = sc.fit_transform(X_test)

print(X_train)
print(X_test)

#Creating models
def models(X_train, Y_train):

  #Logistic Regression
  from sklearn.linear_model import LogisticRegression
  log = LogisticRegression(random_state=0)
  log.fit(X_train, Y_train)

  #Decision Tree
  from sklearn.tree import DecisionTreeClassifier
  tree = DecisionTreeClassifier(criterion='entropy', random_state=0)
  tree.fit(X_train, Y_train)

  #Random Forest Classifier
  from sklearn.ensemble import RandomForestClassifier
  forest = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)
  forest.fit(X_train, Y_train)

  #Printing the models accuracy
  print(' LR Accu: ', log.score(X_train, Y_train))
  print(' DT Accu: ', tree.score(X_train, Y_train))
  print('RFC Accu: ', forest.score(X_train, Y_train))

  return log, tree, forest

#Getting info from all models
model = models(X_train, Y_train)

#Model accuracy for test data
from sklearn.metrics import confusion_matrix

for i in range(len(model)):
  print('Model', i)
  cm = confusion_matrix(Y_test, model[i].predict(X_test))

  TP = cm[0][0]
  TN = cm[1][1]
  FN = cm[1][0]
  FP = cm[0][1]

  print(cm)
  print('Testing Accuracy: ', [(TP + TN) / (TP + TN + FP + FN)])
  print()

#Another way of getting metrics of the models
from sklearn.metrics import classification_report, accuracy_score

for i in range(len(model)):
  print('Model', i)

  print(classification_report(Y_test, model[i].predict(X_test)))
  print('Accuracy:', accuracy_score(Y_test, model[i].predict(X_test)))
  print()

#Predicting by RFC
pred = model[2].predict(X_test)
print(pred)
print()
print(Y_test)

